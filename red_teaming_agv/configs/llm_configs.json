[
    {
        "config_name": "hermes",
        "client": "ollama",
        "model": "hermes3:8b",
        "temperature": 0.7,
        "max_tokens": 1500,
        "api_base": "http://localhost:11434"
    },
    {
        "config_name": "gpt-4o",
        "client": "openai",
        "model": "gpt-4o",
        "temperature": 0.7,
        "max_tokens": 1500,
        "api_base": "https://api.openai.com/v1"
    },
    {
        "config_name": "gpt-4o-mini",
        "client": "openai",
        "model": "gpt-4o-mini",
        "temperature": 0.7,
        "max_tokens": 1500,
        "api_base": "https://api.openai.com/v1"
    },
    {
        "config_name": "deepseek-r1",
        "client": "ollama",
        "model": "deepseek-r1:latest",
        "temperature": 0.7,
        "max_tokens": 1500,
        "api_base": "http://localhost:11434"
    }
]