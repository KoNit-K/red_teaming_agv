[
    {
        "config_name": "attacker_1",
        "client": "ollama",
        "model": "ollama/phi",
        "temperature": 0.7,
        "max_tokens": 1000,
        "api_base": "http://localhost:11434"
    },
    {
        "config_name": "attacker_2",
        "client": "openai",
        "model": "gpt-4o-mini",
        "temperature": 0.7,
        "max_tokens": 1000,
        "api_base": "https://api.openai.com/v1"
    },
    {
        "config_name": "target_1",
        "client": "openai",
        "model": "gpt-4o-mini",
        "temperature": 0.7,
        "max_tokens": 1000,
        "api_base": "https://api.openai.com/v1"
    },
    {
        "config_name": "target_2",
        "client": "anthropic",
        "model": "gemini-2.0-flash",
        "temperature": 0.7,
        "max_tokens": 1000,
        "api_base": "https://generativelanguage.googleapis.com/v1"
    }
]